{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelo NLP - AstraZeneca.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **PLN - Modelo de processo de linguagêm natural**\n",
        "\n",
        "**Análise de sentimento tweets - Vacina AstraZeneca**"
      ],
      "metadata": {
        "id": "LtuI4q6Q1J0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando pacotes\n",
        "!pip install watermark"
      ],
      "metadata": {
        "id": "de-QaY2C2Up2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3tS8TBc0-Ex"
      },
      "outputs": [],
      "source": [
        "# Versão do python\n",
        "from platform import python_version\n",
        "\n",
        "print('Versão Jupyter Notebook neste projeto:', python_version())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importação das bibliotecas\n",
        "\n",
        "# Bibliotecas para NLTK\n",
        "import nltk\n",
        "import re\n",
        "import wordcloud\n",
        "import itertools\n",
        "from wordcloud import WordCloud\n",
        "\n",
        "import pandas as pd # Carregamento de arquivos de csv\n",
        "import numpy as np # Carregamento cálculos em arrays multidimensionais\n",
        "\n",
        "# Bibliotecas de visualização\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Carregar as versões das bibliotecas\n",
        "import watermark\n",
        "\n",
        "# Warnings retirar alertas \n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "-MhSm11O1eYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixando pacote do punkt\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "TdhAy4xr7Tnc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verficações da versões das bibliotecas\n",
        "\n",
        "%reload_ext watermark\n",
        "%watermark -a \"Rafael Gallo\" --iversions"
      ],
      "metadata": {
        "id": "n4quw-tI1ect"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuração fundo dos gráficos e estilo, tamanho da fonte\n",
        "\n",
        "sns.set_palette(\"Accent\")\n",
        "sns.set(style=\"whitegrid\", color_codes=True, font_scale=1.3)\n",
        "color = sns.color_palette()"
      ],
      "metadata": {
        "id": "R58GRDWO1ef1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Base dados**"
      ],
      "metadata": {
        "id": "Fv9sBDY92_mC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Carregando a base de dados\n",
        "df = pd.read_csv(\"Vaccine Tweets-AstraZeneca.csv\")"
      ],
      "metadata": {
        "id": "FpCjbyXv1eiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exebindo o 5 primeiro dados \n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "i8-WMzfw3DS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exebindo o 5 últimos dados\n",
        "df.tail(5)"
      ],
      "metadata": {
        "id": "EdV--yNf3DWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Número de linhas e colunas \n",
        "df.shape"
      ],
      "metadata": {
        "id": "UtfOyPxz3DZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibido os tipos de dados\n",
        "df.dtypes"
      ],
      "metadata": {
        "id": "H5IxcYkh3DcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Informando as informações e das variaveis \n",
        "df.info()"
      ],
      "metadata": {
        "id": "vWtDofHu3DfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total de colunas e linhas \n",
        "\n",
        "print(\"Rows:\", df.shape[0])\n",
        "print(\"Columns:\", df.shape[1])"
      ],
      "metadata": {
        "id": "sFKComnL3DiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibindo valores ausentes e Valores únicos\n",
        "\n",
        "print(\"\\nMissing values :  \", df.isnull().sum().values.sum())\n",
        "print(\"\\nUnique values :  \\n\",df.nunique())"
      ],
      "metadata": {
        "id": "XpNF6vdB3DlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Polaridade do coluna \n",
        "df.Polarity"
      ],
      "metadata": {
        "id": "5Dhbw5Q93Dog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contando números de dados\n",
        "df.Polarity.value_counts()"
      ],
      "metadata": {
        "id": "cEm-RtE73Drn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total de número duplicados\n",
        "df.duplicated()"
      ],
      "metadata": {
        "id": "5j2WgHla3Duo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variação imparcial\n",
        "df.var()"
      ],
      "metadata": {
        "id": "zX3Mx12p3Dxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contagem de dados da coluna account_length\n",
        "\n",
        "df.groupby(['Subjectivity'])['Polarity'].count()"
      ],
      "metadata": {
        "id": "UK1MTtCk3D1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renomeando as colunas do dataset\n",
        "\n",
        "df.columns = [\"Usuario\",\n",
        "              \"Text\",\n",
        "              \"Subjetividade\",\n",
        "              \"Polaridade\",\n",
        "              \"Sentimento\"]\n",
        "df.head()"
      ],
      "metadata": {
        "id": "1rLfRdPx3D4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contagem de dados da coluna na Sentimento\n",
        "df.Sentimento.count()"
      ],
      "metadata": {
        "id": "CK8WUsf55ZQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contagem de dados da coluna na Subjetividade\n",
        "df.Subjetividade.count()"
      ],
      "metadata": {
        "id": "OuLmt8cY5ZTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contagem de dados da coluna na Polaridade\n",
        "df.Polaridade.count()"
      ],
      "metadata": {
        "id": "AwJ5WRUK5ZWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Contagem de dados da coluna na texto\n",
        "df.Text.count()"
      ],
      "metadata": {
        "id": "DC0rbLD-5ZZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Textos duplicados total\n",
        "\n",
        "df.drop_duplicates([\"Text\"], inplace = True)\n",
        "df.Text.count()"
      ],
      "metadata": {
        "id": "CGePMzNL5d9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Análise de dados**"
      ],
      "metadata": {
        "id": "C94f8WFw4G-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico barras de sentimento\n",
        "plt.figure(figsize=(12.8,6))\n",
        "\n",
        "ax = sns.countplot(df[\"Sentimento\"])\n",
        "plt.title(\"Análise de sentimento\")\n",
        "plt.xlabel(\"Sentimentos\")\n",
        "plt.ylabel(\"Total de sentimentos\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-6zTCmCa1els"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de scatterplot \n",
        "plt.figure(figsize=(12.8,6))\n",
        "\n",
        "ax = sns.scatterplot(x=\"Subjetividade\", y=\"Polaridade\", data=df, hue=\"Sentimento\")\n",
        "plt.title(\"Polaridade das frases\")\n",
        "plt.ylabel(\"Total\")\n",
        "plt.xlabel(\"Polaridade e Subjetividade\")"
      ],
      "metadata": {
        "id": "caSYCRv24JWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gráfico de boxplots - Verificando os dados no boxplot valor total verificando possíveis outliers\n",
        "plt.figure(figsize=(12.8,6))\n",
        "\n",
        "ax = sns.boxplot(x=\"Subjetividade\", y=\"Sentimento\", data = df)\n",
        "plt.title(\"Gráfico sentimentos\")\n",
        "plt.xlabel(\"Sentimentos frases\")\n",
        "plt.ylabel(\"Total\")"
      ],
      "metadata": {
        "id": "Zej2N2d94JZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Nuvem de palavras\n",
        "words = ' '.join([tweet for tweet in df['Text']])\n",
        "wordCloud = WordCloud(width=600, height=400).generate(words)\n",
        "\n",
        "plt.figure(figsize=(18.8, 16))\n",
        "plt.imshow(wordCloud)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qKH-6RZc4JcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Treino teste**\n",
        "- Treino e teste da base de dados da colunas textos e sentimento"
      ],
      "metadata": {
        "id": "gEaHGGQR5lGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = df[\"Text\"] # Variável para treino\n",
        "test = df[\"Sentimento\"] # Variável para teste"
      ],
      "metadata": {
        "id": "9UzuGb875kzS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total de linhas e colunas dados variável x\n",
        "train.shape"
      ],
      "metadata": {
        "id": "NmZjPzA74Jei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Total de linhas e colunas dados variável y\n",
        "\n",
        "test.shape"
      ],
      "metadata": {
        "id": "C7xFl--650jC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pré-processamento**"
      ],
      "metadata": {
        "id": "Yxvxy-5n6oLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dados de limpeza para modelo PLN\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Remove stop words: Removendo as stop words na base de dados\n",
        "def remove_stop_words(instancia): # Removendo as stop words\n",
        "    stopwords = set(nltk.corpus.stopwords.words(\"english\"))\n",
        "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
        "    return (\" \".join(palavras))\n",
        "\n",
        "# Palavras derivacionalmente relacionadas com significados semelhantes, palavras para retornar documentos que contenham outra palavra no conjunto.\n",
        "def text_stemming(instancia):\n",
        "    stemmer = nltk.stem.RSLPStemmer()\n",
        "    palavras = []\n",
        "    for w in instancia.split():\n",
        "      palavras.append(stemmer.stem(w))\n",
        "      return (\" \".join(palavras))\n",
        "\n",
        "# Limpeza na base de dados limpando dados de web com http e outros.\n",
        "def dados_limpos(instancia): \n",
        "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
        "    return (instancia)\n",
        "\n",
        "#Lemmatization: Em linguística é o processo de agrupar as formas flexionadas de uma palavra para que possam ser analisadas como um único item, identificado pelo lema da palavra , ou forma de dicionário.\n",
        "def Lemmatization(instancia):\n",
        "    palavras = []\n",
        "    for w in instancia.split():\n",
        "        palavras.append(wordnet_lemmatizer.lemmatize(w))\n",
        "        return (\" \".join(palavras))\n",
        "\n",
        "# Preprocessing: Pré - processamento da base de dados que serão ser para análise de dados.\n",
        "def Preprocessing(instancia):\n",
        "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','').replace('\"','')\n",
        "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
        "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
        "    return (\" \".join(palavras))\n",
        "\n",
        "# Negações do texto\n",
        "def neg(text):\n",
        "    neg = [\"não\", \"not\"]\n",
        "    neg_dect = False\n",
        "    \n",
        "    result = []\n",
        "    pal = text.split()\n",
        "\n",
        "    for x in pal:\n",
        "        x = x.lower()\n",
        "        if neg_dect == True:\n",
        "            x = x + \"_NEG\"\n",
        "        if x in neg:\n",
        "            neg_dect = True\n",
        "        result.append(x)\n",
        "\n",
        "    return (\"\".join(result))"
      ],
      "metadata": {
        "id": "F_J48zPT6ldP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Base dados limpo\n",
        "train = [Preprocessing(i) for i in train]\n",
        "train[:50]"
      ],
      "metadata": {
        "id": "LFIUoSXXHRoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenização as palavras precisam ser codificadas como inteiros, \n",
        "# Ou valores de ponto flutuante, para serem usadas como entradas para modelos machine learning.\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "tokenizer = TweetTokenizer()\n",
        "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer = tokenizer.tokenize)\n",
        "freq = vectorizer.fit_transform(train)\n",
        "freq\n",
        "freq.shape"
      ],
      "metadata": {
        "id": "NCHr0_Eh6lhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo machine learning**\n",
        "\n",
        "- Modelo 01: Regressão logistica"
      ],
      "metadata": {
        "id": "dxq0M_W6846g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo de regressão logistica \n",
        "\n",
        "# Importação da biblioteca\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Nome do algoritmo M.L\n",
        "model_logistic = LogisticRegression() \n",
        "\n",
        "# Treinamento do modelo\n",
        "model_logistic_fit = model_logistic.fit(vet_train, test)\n",
        "\n",
        "# Score do modelo dados treino x\n",
        "model_logistic_score = model_logistic.score(vet_train, test)\n",
        "\n",
        "# Score do modelo dados treino y\n",
        "print(\"Model - Logistic Regression: %.2f\" % (model_logistic_score * 100))"
      ],
      "metadata": {
        "id": "TwnIaStV52N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsão modelo com função predict de previsã das frases\n",
        "\n",
        "model_logistic_pred = model_logistic.predict(vet_train)\n",
        "model_logistic_pred"
      ],
      "metadata": {
        "id": "_aP0sCOf-P1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsão modelo com função log_proba de probabilidades das frases\n",
        "\n",
        "model_logistic_prob = model_logistic.predict_log_proba(vet_train)\n",
        "model_logistic_prob"
      ],
      "metadata": {
        "id": "iCpbe_Q752Q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Acúracia do modelo de Regressão logística\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_dt = accuracy_score(test, model_logistic_pred)\n",
        "print(\"Acurácia - Regressão logística: %.2f\" % (accuracy_dt * 100))"
      ],
      "metadata": {
        "id": "7CrOfCl-9Bj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "matrix_1 = confusion_matrix(model_logistic_pred, test)\n",
        "matrix_1"
      ],
      "metadata": {
        "id": "p6bulpyq9Bm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "classification = classification_report(model_logistic_pred, test)\n",
        "print(\"Modelo - Regressão logística\")\n",
        "print()\n",
        "print(classification)"
      ],
      "metadata": {
        "id": "1-I26Q9S52Tf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot matriz de confusão\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(matrix_1, annot=True, ax = ax, fmt = \".1f\", cmap=\"Paired\"); \n",
        "ax.set_title('Confusion Matrix - Regressão logística'); \n",
        "ax.xaxis.set_ticklabels([\"Positivo\", \"Negativo\", \"Neutro\"]); ax.yaxis.set_ticklabels([\"Positivo\", \"Negativo\", \"Neutro\"]);"
      ],
      "metadata": {
        "id": "-sCSZJ9s9BqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo 02 - Naive bayes**"
      ],
      "metadata": {
        "id": "V0K0BP86_wh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo machine learning - Naive bayes\n",
        "\n",
        "# Importação da biblioteca\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Nome do algoritmo M.L\n",
        "model_naive_bayes = MultinomialNB()\n",
        "\n",
        "# Treinamento do modelo\n",
        "model_naive_bayes_fit = model_naive_bayes.fit(vet_train, test)\n",
        "\n",
        "# Score do modelo dados treino x\n",
        "model_naive_bayes_scor = model_naive_bayes.score(vet_train, test)\n",
        "\n",
        " # Score do modelo dados treino y\n",
        "print(\"Model - Naive Bayes: %.2f\" % (model_naive_bayes_scor * 100))"
      ],
      "metadata": {
        "id": "B1oRJv4F_pBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsão modelo com função predict de previsã das frases\n",
        "\n",
        "model_naive_bayes_pred = model_naive_bayes.predict(vet_train)\n",
        "model_naive_bayes_pred"
      ],
      "metadata": {
        "id": "zIoRI92P_2sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Previsão modelo com função log_proba de probabilidades das frases\n",
        "\n",
        "model_naive_bayes_prob = model_naive_bayes.predict_proba(vet_train).round(2)\n",
        "print(model_naive_bayes_prob)"
      ],
      "metadata": {
        "id": "zQFSyJKZ_2u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Acúracia do modelo de Naive bayes\n",
        "accuracy_naive_bayes = metrics.accuracy_score(test, model_naive_bayes_pred)\n",
        "\n",
        "print(\"Accuracy model Naive bayes: %.2f\" % (accuracy_naive_bayes * 100))"
      ],
      "metadata": {
        "id": "9glSwoIM_2x5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix\n",
        "matrix_2 = confusion_matrix(model_naive_bayes_pred, test)\n",
        "matrix_2"
      ],
      "metadata": {
        "id": "qWtlYEne_20e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "classification = classification_report(model_naive_bayes_pred, test)\n",
        "print(\"Modelo - Naive bayes\")\n",
        "print()\n",
        "print(classification)"
      ],
      "metadata": {
        "id": "-q_pozx0ANb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(matrix_2, annot=True, ax = ax, fmt = \".1f\", cmap=\"Paired\"); \n",
        "ax.set_title('Confusion Matrix - Naive bayes'); \n",
        "ax.xaxis.set_ticklabels([\"Positivo\", \"Negativo\", \"Neutro\"]); ax.yaxis.set_ticklabels([\"Positivo\", \"Negativo\", \"Neutro\"]);"
      ],
      "metadata": {
        "id": "3pDhLPoF_23r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pipeline 1 - Regressão logística**"
      ],
      "metadata": {
        "id": "S2CphQAEA7N1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Função para texto de negações\n",
        "def marque_negacao(texto):\n",
        "    \n",
        "    # Negaçoes do texto mudando para not para \"não\"\n",
        "    negacoes = ['não','not']\n",
        "    negacao_detectada = False\n",
        "    \n",
        "    # Criando uma lista vazia \n",
        "    resultado = []\n",
        "    palavras = texto.split()\n",
        "    \n",
        "    # For em palavras para os dados de negações \n",
        "    for p in palavras:\n",
        "        p = p.lower()\n",
        "        if negacao_detectada == True:\n",
        "            p = p + '_NEG'\n",
        "        if p in negacoes:\n",
        "            negacao_detectada = True\n",
        "        resultado.append(p)\n",
        "    \n",
        "    # Retornando a função\n",
        "    return (\" \".join(resultado))"
      ],
      "metadata": {
        "id": "2lQFUgFeAJz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando bibliotecas do pipeline\n",
        "from sklearn import svm\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Pipeline modelo regressão logística\n",
        "model_reg_log = Pipeline([\n",
        "    ('counts', CountVectorizer()),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Treinamento do pipeline \n",
        "model_reg_log.fit(train, test)\n",
        "\n",
        "# Pipeline simples \n",
        "model_reg_log_simples = Pipeline([\n",
        "  ('counts', CountVectorizer()),\n",
        "  ('classifier', LogisticRegression())\n",
        "])\n",
        "\n",
        "# Treinamento do pipeline\n",
        "model_reg_log_simples.fit(train, test)\n",
        "\n",
        "# Pipeline para negações\n",
        "model_reg_log_negacoes = Pipeline([\n",
        "  ('counts', CountVectorizer(tokenizer=lambda text: marque_negacao(text))),\n",
        "  ('classifier', LogisticRegression())\n",
        "])\n",
        "# Treinamento do pipeline\n",
        "model_reg_log_negacoes.fit(train, test)"
      ],
      "metadata": {
        "id": "Ajf-KEbSBkze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validação cruzada do modelo\n",
        "validacao_cruzada_Reg = cross_val_predict(model_reg_log, train, test)\n",
        "validacao_cruzada_Reg"
      ],
      "metadata": {
        "id": "CnJ_7BQvDQAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Acúracia do modelo do pipeline regressão logística\n",
        "accuracy_1_rg = metrics.accuracy_score(test, validacao_cruzada_Reg)\n",
        "\n",
        "print(\"Accuracy pipeline 1 Logistic Regression: %.2f\" % (accuracy_1_rg * 100))"
      ],
      "metadata": {
        "id": "Xvw7sxfRAJ58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report do pipeline \n",
        "classification = classification_report(validacao_cruzada_Reg, test)\n",
        "print(\"Modelo - Pipeline 1 regressão logística\")\n",
        "print()\n",
        "print(classification)"
      ],
      "metadata": {
        "id": "x9SjIE0BDBdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix pipeline regressão logística\n",
        "matrix_3 = confusion_matrix(validacao_cruzada_Reg, test)\n",
        "matrix_3"
      ],
      "metadata": {
        "id": "2yG5Nd5VAJ86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz total de sentimentos\n",
        "\n",
        "sentimento=['Positivo',\n",
        "            'Negativo',\n",
        "            'Neutro']\n",
        "\n",
        "print(pd.crosstab(test, validacao_cruzada_Reg, rownames = [\"Real\"], colnames=[\"Predito\"], margins = True))"
      ],
      "metadata": {
        "id": "XERhQcSnD1zc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(matrix_3, annot=True, ax = ax, fmt = \".1f\", cmap=\"Paired\"); \n",
        "ax.set_title('Confusion Matrix - Pipeline 1 regressão logística'); \n",
        "ax.xaxis.set_ticklabels([\"Positivo\", \"Negativo\", \"Neutro\"]); ax.yaxis.set_ticklabels([\"Positivo\", \"Negativo\", \"Neutro\"]);"
      ],
      "metadata": {
        "id": "9OOfFOHKAJ_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pipeline 2 - Naive bayes**"
      ],
      "metadata": {
        "id": "Rf879Xp9EPr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline simples naive bayes\n",
        "model_pipeline_simples_2 = Pipeline([\n",
        "  ('counts', CountVectorizer()),\n",
        "  ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Treinamento do pipeline\n",
        "model_pipeline_simples_2.fit(train, test)\n",
        "\n",
        "# Pipeline negações\n",
        "model_pipeline_negacoes_2 = Pipeline([\n",
        "  ('counts', CountVectorizer(tokenizer=lambda text: marque_negacao(text))),\n",
        "  ('classifier', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Pipeline treinamento\n",
        "model_pipeline_negacoes_2.fit(train, test)\n",
        "\n",
        "# Pipeline SVM simples\n",
        "model_pipeline_svm_simples_2 = Pipeline([\n",
        "    (\"counts\", CountVectorizer()),\n",
        "    (\"classifier\", svm.SVC(kernel = \"linear\"))\n",
        "])\n",
        "# Treinamento pipeline\n",
        "model_pipeline_svm_simples_2.fit(train, test)\n",
        "\n",
        "# Pipeline SVM para negacoes\n",
        "model_pipeline_svm_negacoes_2 = Pipeline([\n",
        "    (\"counts\", CountVectorizer(tokenizer = lambda text: marque_negacao(text))),\n",
        "    (\"classifier\", svm.SVC(kernel = \"linear\"))\n",
        "])\n",
        "\n",
        "# Treinamento do pipeline\n",
        "model_pipeline_svm_negacoes_2.fit(train, test)"
      ],
      "metadata": {
        "id": "05HzynSzDeXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Validação cruzada pipeline naive bayes\n",
        "validacao_cruzada_2 = cross_val_predict(model_pipeline_simples_2, train, test)\n",
        "validacao_cruzada_2"
      ],
      "metadata": {
        "id": "UwVt3uTNDeap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Acúracia do modelo do pipeline naive bayes\n",
        "accuracy_pipeline_2_nb = metrics.accuracy_score(test, validacao_cruzada_2)\n",
        "print(\"Accuracy pipeline 2 - Naive bayes: %.2f\" % (accuracy_pipeline_2_nb * 100))"
      ],
      "metadata": {
        "id": "kGCp97uKDedP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report do pipeline 2 \n",
        "classification = classification_report(validacao_cruzada_2, test)\n",
        "print(\"Modelo - Pipeline 2 naive bayes\")\n",
        "print()\n",
        "print(classification)"
      ],
      "metadata": {
        "id": "YycRKBM_DegD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Matriz total de sentimentos\n",
        "sentimento=['Positivo',\n",
        "            'Negativo',\n",
        "            'Neutro']\n",
        "\n",
        "print(pd.crosstab(test, \n",
        "                  validacao_cruzada_2, \n",
        "                  rownames = [\"Real\"], \n",
        "                  colnames=[\"Predito\"], \n",
        "                  margins = True))"
      ],
      "metadata": {
        "id": "Z15pvD0bFfiY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Confusion matrix pipeline 2 naive bayes\n",
        "matrix_4 = confusion_matrix(validacao_cruzada_2, test)\n",
        "matrix_4"
      ],
      "metadata": {
        "id": "g8LnQ0Q1Ffnl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(15, 8))\n",
        "\n",
        "ax = plt.subplot()\n",
        "sns.heatmap(matrix_4, annot=True, ax = ax, fmt = \".1f\", cmap=\"Paired\"); \n",
        "ax.set_title('Confusion Matrix - Pipeline 1 regressão logística'); \n",
        "ax.xaxis.set_ticklabels([\"Positivo\", \"Negativo\", \"Neutro\"]); ax.yaxis.set_ticklabels([\"Positivo\", \"Negativo\", \"Neutro\"]);"
      ],
      "metadata": {
        "id": "D1wmQvD6Feob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Métricas do modelos - Naive Nayes e regressão logística\n",
        "def metricas_pipeline(model_naive_bayes, train, test):\n",
        "    validacao_cruzada = cross_val_predict(model_naive_bayes, train, test, cv = 10)\n",
        "    return \"Acurácia do modelo: {}\".format(metrics.accuracy_score(validacao_cruzada, test))\n",
        "\n",
        "def metricas_pipeline(model_logistic, train, test):\n",
        "    validacao_cruzada_Reg = cross_val_predict(model_logistic, train, test, cv = 10)\n",
        "    return \"Acurácia do modelo: {}\".format(metrics.accuracy_score(validacao_cruzada_Reg, test))\n",
        "\n",
        "print(\"Pipeline 1 - Naive Bayes\")\n",
        "print()\n",
        "print(\"Model pipeline Naive Bayes Simples:\", metricas_pipeline(model_pipeline_simples, train, test))\n",
        "print(\"Model pipeline Naive Bayes negações:\", metricas_pipeline(model_pipeline_negacoes, train, test))\n",
        "print(\"Model pipeline SVM simples:\", metricas_pipeline(model_pipeline_svm_simples, train, test))\n",
        "print(\"Model pipeline SVM negacoes:\", metricas_pipeline(model_pipeline_svm_negacoes, train, test))\n",
        "print()\n",
        "print(\"Pipeline 2 - Regressão Logística\")\n",
        "print()\n",
        "print(\"Model pipeline Simples:\", metricas_pipeline(model_reg_log, train, test))\n",
        "print(\"Model pipeline negações:\", metricas_pipeline(model_reg_log_simples, train, test))\n",
        "print(\"Model pipeline SVM simples:\", metricas_pipeline(model_reg_log_negacoes, train, test))"
      ],
      "metadata": {
        "id": "DqLaj4z7GBbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Resultados - Modelos machine learning\n",
        "\n",
        "modelos = pd.DataFrame({\n",
        "    \n",
        "    \"Models\" :[\"Pipeline 1 - Regressão logistica\", \n",
        "               \"Pipeline 2 - Naive Bayes\"],\n",
        "\n",
        "    \"Acurácia\" :[accuracy_pipeline_2_nb,\n",
        "                 accuracy_1_rg]})\n",
        "\n",
        "modelos.sort_values(by = \"Acurácia\", ascending = False)"
      ],
      "metadata": {
        "id": "VcJARowaF_Vp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Salvando modelo M.L\n",
        "\n",
        "import pickle\n",
        " \n",
        "with open('model_logistic_pred.pkl', 'wb') as file:\n",
        "    pickle.dump(model_logistic_pred, file)\n",
        "    \n",
        "with open('model_naive_bayes_pred.pkl', 'wb') as file:\n",
        "    pickle.dump(model_naive_bayes_pred, file)"
      ],
      "metadata": {
        "id": "-5-iQZauF_Zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "50BqeS0DF_cj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}