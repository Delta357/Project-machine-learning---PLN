{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = pd.read_csv(\"imdb-reviews-pt-br.csv\")\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dados.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificacao = dados[\"sentiment\"].replace([\"neg\", \"pos\"], [0, 1])\n",
    "dados[\"classificacao\"] = classificacao\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualização de dados NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.distplot(dados[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.countplot(dados[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.title(\"Classificação de sentimentos positivos e negativos\")\n",
    "plt.ylabel(\"Negativos\")\n",
    "plt.hist(dados[\"classificacao\"]);\n",
    "plt.legend([\"Positivo\", \"Negativo\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = dados.corr()\n",
    "ma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = sns.heatmap(ma, annot = True, fmt = \".1f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.pairplot(dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criando representações da linguagem humana**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Negativa \\n\")\n",
    "print(dados.text_pt[189])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Positivo \\n\", dados.text_pt[49002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "texto = [\"Hoje não estou feliz\"]\n",
    "\n",
    "vet = CountVectorizer(lowercase=False)\n",
    "bag_of_words = vet.fit_transform(texto)\n",
    "\n",
    "matriz_esparsa = pd.DataFrame.sparse.from_spmatrix(bag_of_words, columns = vet.get_feature_names())\n",
    "matriz_esparsa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vetorizar = CountVectorizer(lowercase=False, max_features=50)\n",
    "bag_of_words = vetorizar.fit_transform(dados.text_pt)\n",
    "print(bag_of_words.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizando os dados com WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resenha_positiva = dados.query(\"sentiment == 'pos'\")\n",
    "resenha_positiva.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resenha_negativa = dados.query(\"sentiment == 'neg'\")\n",
    "resenha_negativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "todos_palavras = ' '.join([texto for texto in dados[\"text_pt\"]])\n",
    "nuvem_palavras = WordCloud(width = 800, height = 500, max_font_size = 110,\n",
    "                          collocations = False).generate(todos_palavras)\n",
    "\n",
    "plt.figure(figsize= (10, 7))\n",
    "plt.imshow(nuvem_palavras, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_pos = ' '.join([texto for texto in resenha_positiva[\"text_pt\"]])\n",
    "nuvem_palavras = WordCloud(width=800, height=500, max_font_size=110,\n",
    "                           collocations=False).generate(palavras_pos)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(nuvem_palavras, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_neg = ' '.join([texto for texto in resenha_negativa[\"text_pt\"]])\n",
    "nuvem_palavras = WordCloud(width=800, height=500, max_font_size=110,\n",
    "                           collocations=False).generate(palavras_neg)\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(nuvem_palavras, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import tokenize\n",
    "\n",
    "frase = \"Bem vindo ao mundo do PLN\"\n",
    "token_espaco = tokenize.WhitespaceTokenizer()\n",
    "token_frase = token_espaco.tokenize(frase)\n",
    "print(token_frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_palavras = ' '.join([texto for texto in dados[\"text_pt\"]])\n",
    "frequencia = nltk.FreqDist(token_espaco.tokenize(todas_palavras))\n",
    "df_frequencia = pd.DataFrame({\"Palavra\": list(frequencia.keys()),\n",
    "                             \"Frequência\": list(frequencia.values())})\n",
    "\n",
    "df_frequencia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_frequencia = df_frequencia.nlargest(columns = \"Frequência\", n = 10)\n",
    "df_frequencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "ax = sns.barplot(data = df_frequencia, x= \"Palavra\", y = \"Frequência\", color = 'gray')\n",
    "ax.set(ylabel = \"Contagem\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_irrelevantes = nltk.corpus.stopwords.words(\"portuguese\")\n",
    "frase_processada = list()\n",
    "\n",
    "for opiniao in dados[\"text_pt\"]:\n",
    "    nova_frase = list()\n",
    "    palavras_texto = token_espaco.tokenize(opiniao)\n",
    "    for palavra in palavras_texto:\n",
    "        if palavra not in palavras_irrelevantes:\n",
    "            nova_frase.append(palavra)\n",
    "    frase_processada.append(' '.join(nova_frase))\n",
    "    \n",
    "dados[\"tratamento_1\"] = frase_processada\n",
    "dados.head()\n",
    "\n",
    "print(\"Frase text_pr\\n\")\n",
    "print(dados[\"text_pt\"][0])\n",
    "print(\"\\n Frase tratamento_1\\n\")\n",
    "print(dados[\"tratamento_1\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuvem_palavras_neg(texto, coluna_texto):\n",
    "    texto_negativo = texto.query(\"sentiment == 'neg'\")\n",
    "    todas_palavras = ' '.join([texto for texto in texto_negativo[coluna_texto]])\n",
    "    nuvem_palavras = WordCloud(width = 800, height = 500,\n",
    "                                max_font_size=110, collocations=False).generate(todas_palavras)\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.imshow(nuvem_palavras, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "nuvem_palavras_neg(dados, \"tratamento_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nuvem_palavras_pos(texto, coluna_texto):\n",
    "    texto_positivo = texto.query(\"sentiment == 'pos'\")\n",
    "    todas_palavras = ' '.join([texto for texto in texto_positivo[coluna_texto]])\n",
    "    nuvem_palavras = WordCloud(width = 800, height = 500,\n",
    "                                max_font_size=110, collocations=False).generate(todas_palavras)\n",
    "    plt.figure(figsize=(10,7))\n",
    "    plt.imshow(nuvem_palavras, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "nuvem_palavras_pos(dados, \"tratamento_1\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pareto(texto, coluna_texto, quantidade):\n",
    "    todas_palavras = ' '.join([texto for texto in texto[coluna_texto]])\n",
    "    frequencia = nltk.FreqDist(token_espaco.tokenize(todas_palavras))\n",
    "    df_frequencia = pd.DataFrame({\"Palavra\": list(frequencia.keys()),\n",
    "                                 \"Frequência\": list(frequencia.values())})\n",
    "    df_frequencia = df_frequencia.nlargest(columns = \"Frequência\", n = quantidade)\n",
    "    plt.figure(figsize=(12,8))\n",
    "    ax = sns.barplot(data = df_frequencia, x= \"Palavra\", y = \"Frequência\", color = 'gray')\n",
    "    ax.set(ylabel = \"Contagem\")\n",
    "    plt.show()   \n",
    "\n",
    "pareto(dados, \"tratamento_1\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def classificar_texto(texto, coluna_texto, coluna_classificacao):\n",
    "    vetorizar = CountVectorizer(lowercase=False, max_features=50)\n",
    "    bag_of_words = vetorizar.fit_transform(texto[coluna_texto])\n",
    "    treino, teste, classe_treino, classe_teste = train_test_split(bag_of_words,\n",
    "                                                                 texto[coluna_classificacao],\n",
    "                                                                 random_state = 42)\n",
    "    \n",
    "    regressao_logistica = LogisticRegression(solver=\"lbfgs\")\n",
    "    regressao_logistica.fit(treino, classe_treino)\n",
    "    \n",
    "    return regressao_logistica.score(teste, classe_teste)\n",
    "\n",
    "acuracia_teste = classificar_texto(dados, \"tratamento_1\", \"classificacao\")\n",
    "print(acuracia_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo PLN 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "regressao_logistica = LogisticRegression(solver = \"lbfgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "\n",
    "frase = \"Olá mundo!\"\n",
    "token_pontuacao = tokenize.WordPunctTokenizer()\n",
    "token_frase = token_pontuacao.tokenize(frase)\n",
    "token_frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "\n",
    "pontuacao = list()\n",
    "for ponto in punctuation:\n",
    "    pontuacao.append(ponto)\n",
    "\n",
    "pontuacao_stopwords = pontuacao + palavras_irrelevantes\n",
    "\n",
    "frase_processada = list()\n",
    "for opiniao in dados[\"tratamento_1\"]:\n",
    "    nova_frase = list()\n",
    "    palavras_texto = token_pontuacao.tokenize(opiniao)\n",
    "    for palavra in palavras_texto:\n",
    "        if palavra not in pontuacao_stopwords:\n",
    "            nova_frase.append(palavra)\n",
    "    frase_processada.append(' '.join(nova_frase))\n",
    "    \n",
    "dados[\"tratamento_2\"] = frase_processada\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados[\"tratamento_1\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados[\"tratamento_2\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto(dados, \"tratamento_2\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "acentos = \"Ótimo péssimo não é tão\"\n",
    "teste = unidecode.unidecode(acentos)\n",
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_acentos = [unidecode.unidecode(texto) for texto in dados[\"tratamento_2\"]]\n",
    "sem_acentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_sem_acento = [unidecode.unidecode(texto) for texto in pontuacao_stopwords]\n",
    "stopwords_sem_acento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados[\"tratamento_3\"] = sem_acentos\n",
    "\n",
    "frase_processada = list()\n",
    "for opiniao in dados[\"tratamento_3\"]:\n",
    "    nova_frase = list()\n",
    "    palavras_texto = token_pontuacao.tokenize(opiniao)\n",
    "    for palavra in palavras_texto:\n",
    "        if palavra not in stopwords_sem_acento:\n",
    "            nova_frase.append(palavra)\n",
    "    frase_processada.append(' '.join(nova_frase))\n",
    "    \n",
    "dados[\"tratamento_3\"] = frase_processada\n",
    "\n",
    "acuracia_tratamento3 = classificar_texto(dados, \"tratamento_3\", \"classificacao\")\n",
    "print(acuracia_tratamento3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase_processada = list()\n",
    "for opiniao in dados[\"tratamento_3\"]:\n",
    "    nova_frase = list()\n",
    "    opiniao = opiniao.lower()\n",
    "    palavras_texto = token_pontuacao.tokenize(opiniao)\n",
    "    for palavra in palavras_texto:\n",
    "        if palavra not in stopwords_sem_acento:\n",
    "            nova_frase.append(palavra)\n",
    "    frase_processada.append(' '.join(nova_frase))\n",
    "    \n",
    "dados[\"tratamento_4\"] = frase_processada\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados[\"text_pt\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados[\"tratamento_4\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_tratamento4 = classificar_texto(dados, \"tratamento_4\", \"classificacao\")\n",
    "print(acuracia_tratamento4)\n",
    "print(acuracia_tratamento3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuvem_palavras_neg(dados, \"tratamento_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuvem_palavras_pos(dados, \"tratamento_4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto(dados, \"tratamento_4\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.RSLPStemmer()\n",
    "st = stemmer.stem(\"correria\")\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frase_processada = list()\n",
    "for opiniao in dados[\"tratamento_4\"]:\n",
    "    nova_frase = list()\n",
    "    palavras_texto = token_pontuacao.tokenize(opiniao)\n",
    "    for palavra in palavras_texto:\n",
    "        if palavra not in stopwords_sem_acento:\n",
    "            nova_frase.append(stemmer.stem(palavra))\n",
    "    frase_processada.append(' '.join(nova_frase))\n",
    "    \n",
    "dados[\"tratamento_5\"] = frase_processada\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acuracia_tratamento5 = classificar_texto(dados, \"tratamento_5\", \"classificacao\")\n",
    "print(acuracia_tratamento5)\n",
    "print(acuracia_tratamento4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuvem_palavras_neg(dados, \"tratamento_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuvem_palavras_pos(dados,\"tratamento_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pareto(dados, \"tratamento_5\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "frases = [\"Assiti um filme ótimo\", \"Assiti um filme péssimo\"]\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase = False, max_features = 50)\n",
    "caracteristicas = tfidf.fit_transform(frases)\n",
    "\n",
    "pd.DataFrame(\n",
    "caracteristicas.todense(),\n",
    "columns = tfidf.get_feature_names()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_bruto = tfidf.fit_transform(dados[\"text_pt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_tratados = tfidf.fit_transform(dados[\"tratamento_5\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treino e teste 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treino e teste\n",
    "\n",
    "treino, teste, classe_treino, classe_teste = train_test_split(tfidf_tratados,\n",
    "                                                              dados[\"classificacao\"],\n",
    "                                                              random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe_treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressao_logistica.fit(treino, classe_treino)\n",
    "acuracia_tfidf_tratados = regressao_logistica.score(teste, classe_teste)\n",
    "print(acuracia_tfidf_tratados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acuracia_tratamento5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "\n",
    "frase = \"Assisti um ótimo filme.\"\n",
    "frase_separada = token_espaco.tokenize(frase)\n",
    "frase_separada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pares = ngrams(frase_separada, 2)\n",
    "pares\n",
    "list(pares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treino e teste 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(lowercase=False, ngram_range = (1,2))\n",
    "tfidf = TfidfVectorizer(lowercase=False)\n",
    "vetor_tfidf = tfidf.fit_transform(dados[\"tratamento_5\"])\n",
    "treino, teste, classe_treino, classe_teste = train_test_split(vetor_tfidf,\n",
    "                                                              dados[\"classificacao\"],\n",
    "                                                              random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treino.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe_treino.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de regressão logistica  (Melhorado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressao_logistica.fit(treino, classe_treino)\n",
    "reg_log = regressao_logistica.score(teste, classe_teste)\n",
    "print(reg_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pesos = pd.DataFrame(\n",
    "    regressao_logistica.coef_[0].T,\n",
    "    index = tfidf.get_feature_names()\n",
    ")\n",
    "\n",
    "pesos.nlargest(50,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pesos.nsmallest(10,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
